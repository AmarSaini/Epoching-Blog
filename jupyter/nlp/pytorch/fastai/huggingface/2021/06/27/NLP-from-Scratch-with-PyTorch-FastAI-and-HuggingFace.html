<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>NLP from Scratch with PyTorch, fastai, and HuggingFace | Epoching’s Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="NLP from Scratch with PyTorch, fastai, and HuggingFace" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A technical NLP tutorial using a variety of libraries to show the different levels/layers of common NLP pipelines" />
<meta property="og:description" content="A technical NLP tutorial using a variety of libraries to show the different levels/layers of common NLP pipelines" />
<link rel="canonical" href="https://amarsaini.github.io/Epoching-Blog/jupyter/nlp/pytorch/fastai/huggingface/2021/06/27/NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.html" />
<meta property="og:url" content="https://amarsaini.github.io/Epoching-Blog/jupyter/nlp/pytorch/fastai/huggingface/2021/06/27/NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.html" />
<meta property="og:site_name" content="Epoching’s Blog" />
<meta property="og:image" content="https://amarsaini.github.io/Epoching-Blog/images/pfh.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-06-27T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://amarsaini.github.io/Epoching-Blog/jupyter/nlp/pytorch/fastai/huggingface/2021/06/27/NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.html","@type":"BlogPosting","headline":"NLP from Scratch with PyTorch, fastai, and HuggingFace","dateModified":"2021-06-27T00:00:00-05:00","datePublished":"2021-06-27T00:00:00-05:00","image":"https://amarsaini.github.io/Epoching-Blog/images/pfh.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://amarsaini.github.io/Epoching-Blog/jupyter/nlp/pytorch/fastai/huggingface/2021/06/27/NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.html"},"description":"A technical NLP tutorial using a variety of libraries to show the different levels/layers of common NLP pipelines","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Epoching-Blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://amarsaini.github.io/Epoching-Blog/feed.xml" title="Epoching's Blog" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-57531313-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-57531313-5');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/Epoching-Blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Epoching-Blog/">Epoching&#39;s Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Epoching-Blog/about/">About Me</a><a class="page-link" href="/Epoching-Blog/search/">Search</a><a class="page-link" href="/Epoching-Blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">NLP from Scratch with PyTorch, fastai, and HuggingFace</h1><p class="page-description">A technical NLP tutorial using a variety of libraries to show the different levels/layers of common NLP pipelines</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-06-27T00:00:00-05:00" itemprop="datePublished">
        Jun 27, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      37 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Epoching-Blog/categories/#jupyter">jupyter</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Epoching-Blog/categories/#nlp">nlp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Epoching-Blog/categories/#pytorch">pytorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Epoching-Blog/categories/#fastai">fastai</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Epoching-Blog/categories/#huggingface">huggingface</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/AmarSaini/Epoching-Blog/tree/master/_notebooks/2021-06-27-NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Epoching-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/AmarSaini/Epoching-Blog/master?filepath=_notebooks%2F2021-06-27-NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Epoching-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/AmarSaini/Epoching-Blog/blob/master/_notebooks/2021-06-27-NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Epoching-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#0.-Introduction">0. Introduction </a></li>
<li class="toc-entry toc-h1"><a href="#1.-Looking-at-the-Data-[Pandas]">1. Looking at the Data [Pandas] </a></li>
<li class="toc-entry toc-h1"><a href="#2.-Tokenization-and-Numericalization-[PyTorch]">2. Tokenization and Numericalization [PyTorch] </a></li>
<li class="toc-entry toc-h1"><a href="#3.-Dataset-&-DataLoaders-[PyTorch-&-fastai]">3. Dataset &amp; DataLoaders [PyTorch &amp; fastai] </a></li>
<li class="toc-entry toc-h1"><a href="#4.-Model-[PyTorch]">4. Model [PyTorch] </a></li>
<li class="toc-entry toc-h1"><a href="#5.-Training/Fitting-[fastai]">5. Training/Fitting [fastai] </a></li>
<li class="toc-entry toc-h1"><a href="#6.-Using-a-Language-Model-via-AWD-LSTM-[fastai]">6. Using a Language Model via AWD-LSTM [fastai] </a></li>
<li class="toc-entry toc-h1"><a href="#7.-Using-a-Language-Model-via-DistilBERT-[HuggingFace-&-PyTorch-&-fastai]">7. Using a Language Model via DistilBERT [HuggingFace &amp; PyTorch &amp; fastai] </a></li>
<li class="toc-entry toc-h1"><a href="#8.-Conclusion">8. Conclusion </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-06-27-NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="0.-Introduction">
<a class="anchor" href="#0.-Introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>0. Introduction<a class="anchor-link" href="#0.-Introduction"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Welcome! In this blog post/notebook, we'll be looking at NLP with 3 different methods:</p>
<ul>
<li>From Scratch/Ground-Up, with <a href="https://pytorch.org/">PyTorch</a>
</li>
<li>FastAI Language Model (<a href="https://docs.fast.ai/text.models.awdlstm.html#AWD_LSTM">AWD-LSTM</a>)</li>
<li>HuggingFace Transformers (<a href="https://huggingface.co/transformers/model_doc/distilbert.html">DistilBERT</a>)</li>
</ul>
<p>All 3 methods will utilize fastai to assist with keeping things organized and help with training the models, given the libary's ease of use through it's lovely <a href="https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/">Layered-API</a>!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="1.-Looking-at-the-Data-[Pandas]">
<a class="anchor" href="#1.-Looking-at-the-Data-%5BPandas%5D" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Looking at the Data [Pandas]<a class="anchor-link" href="#1.-Looking-at-the-Data-%5BPandas%5D"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For this notebook, we'll be looking at the Amazon Reviews Polarity dataset! The task is to predict whether a review is of positive or negative sentiment. The original Amazon Reviews dataset contains review scores ranging from 1-5. This polarity dataset combines review scores 1-2 into the negative class, 4-5 into the positive class, and ignores/drops review scores of 3!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">AMAZON_REVIEWS_POLARITY</span><span class="p">)</span>
<span class="n">path</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Path('/home/saini5/.fastai/data/amazon_review_polarity_csv')</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#3) [Path('/home/saini5/.fastai/data/amazon_review_polarity_csv/train.csv'),Path('/home/saini5/.fastai/data/amazon_review_polarity_csv/readme.txt'),Path('/home/saini5/.fastai/data/amazon_review_polarity_csv/test.csv')]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's go ahead and take a look at our two df's: <code>train_df</code> and <code>valid_df</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>We’re going to use 40k instead of 3.6m samples for training, and 2k instead of 400k samples for validation
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'train.csv'</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'label'</span><span class="p">,</span> <span class="s1">'title'</span><span class="p">,</span> <span class="s1">'text'</span><span class="p">],</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">40000</span><span class="p">)</span>
<span class="n">valid_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">'test.csv'</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">'label'</span><span class="p">,</span> <span class="s1">'title'</span><span class="p">,</span> <span class="s1">'text'</span><span class="p">],</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>title</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>Stuning even for the non-gamer</td>
      <td>This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>The best soundtrack ever to anything.</td>
      <td>I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Amazing!</td>
      <td>This soundtrack is my favorite music of all time, hands down. The intense sadness of "Prisoners of Fate" (which means all the more if you've played the game) and the hope in "A Distant Promise" and "Girl who Stole the Star" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like "Chrono Cross ~ Time's Scar~", "Time of the Dreamwatch", and "Chronomantique" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears s...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>Excellent Soundtrack</td>
      <td>I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Uns...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>Remember, Pull Your Jaw Off The Floor After Hearing it</td>
      <td>If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>label 1 is negative sentiment and label 2 is positive sentiment
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(40000, 2000)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="2.-Tokenization-and-Numericalization-[PyTorch]">
<a class="anchor" href="#2.-Tokenization-and-Numericalization-%5BPyTorch%5D" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Tokenization and Numericalization [PyTorch]<a class="anchor-link" href="#2.-Tokenization-and-Numericalization-%5BPyTorch%5D"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now want to first tokenize our inputs, then numericalize them using a vocab. Quick recap of these terms:</p>
<ul>
<li>
<em>Tokenization</em> = The process of converting an input string into "pieces"<ul>
<li>These pieces can be <strong>whole words</strong>, <strong>sub words</strong>, or even <strong>characters</strong>
</li>
</ul>
</li>
<li>
<em>Numericalization</em> = The process of converting a token into a numeric representation<ul>
<li>(e.g. token -&gt; number)</li>
<li>This is done through the use (and creation of) a <strong>vocab</strong>
</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are many fancy tokenizers out there, but since we're first doing things from scratch we'll go ahead and use a simple <code>basic_english</code> tokenizer from <code>torchtext</code> and split on spaces</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>More popular tokenizer pipelines can be found in libraries such as <a href="https://spacy.io/api/tokenizer">SpaCy</a>, <a href="https://huggingface.co/transformers/main_classes/tokenizer.html">HuggingFace</a>, and <a href="https://docs.fast.ai/text.core.html#Tokenizing">fastai</a>!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_text</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sample_text</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchtext</span>
<span class="kn">from</span> <span class="nn">torchtext.data</span> <span class="kn">import</span> <span class="n">get_tokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">"basic_english"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Reminder that fastai’s <code>L</code> is basically <code>list</code> from Python, but has some convienent properties such as displaying the number of elements, and  additionally doesn’t spam your screen with output if the list is too long!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">))</span>
<span class="n">tokens</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#81) ['this','sound','track','was','beautiful','!','it','paints','the','senery'...]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Since we’re using a full word tokenizer, many of these words will be quite infrequent, such as typos or words with repetiting characters like <code>Dudeeeee</code>. Other tokenizers can use rules to better handle splitting of big words through subword tokenization, and can also handle numbers like prices as well. This would help with optimizing the <strong>vocab’s embedding table</strong> as well as reducing the number of <code>&lt;unk&gt;</code> tokens.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we'll need to check how many tokens there are in our dataset, and keep the frequent ones as part of our vocab.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="n">token_counter</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

<span class="k">for</span> <span class="n">sample_text</span> <span class="ow">in</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]:</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)</span>
    <span class="n">token_counter</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

<span class="n">token_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('.', 213962),
 ('the', 158787),
 (',', 116525),
 ('i', 91270),
 ('and', 86059),
 ('a', 77977),
 ('to', 74984),
 ('it', 69999),
 ('of', 65144),
 ("'", 60523),
 ('this', 59382),
 ('is', 56445),
 ('in', 37890),
 ('that', 33891),
 ('for', 30532),
 ('was', 29163),
 ('you', 26740),
 ('!', 25238),
 ('book', 24698),
 ('s', 23897),
 ('but', 22602),
 ('with', 21998),
 ('not', 21988),
 ('on', 20759),
 ('t', 20097)]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>The top 25 most common tokens are listed above! Let’s see what the least frequent tokens look like:
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">token_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">()[</span><span class="o">-</span><span class="mi">25</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[('knorflefob', 1),
 ('&lt;&lt;dan', 1),
 ('bg', 1),
 ('apquire$', 1),
 ('gtube', 1),
 ('chafe', 1),
 ('lubricates', 1),
 ('lubricate', 1),
 ('flights/vacation', 1),
 ('lambdin', 1),
 ('trafalgar', 1),
 ('bloodedly', 1),
 ('undifferentiated', 1),
 ('code--no', 1),
 ('exciting--because', 1),
 ('nicaea', 1),
 ('full-grown', 1),
 ('yon', 1),
 ('medium-to-large', 1),
 ('ms-supplied', 1),
 ('well@@', 1),
 ('in-touch', 1),
 ('*ms', 1),
 ('specialist*', 1),
 ('schapiro', 1)]</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">token_counter</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>75889</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">token_counter</span><span class="p">[</span><span class="s1">'well@@'</span><span class="p">],</span> <span class="n">token_counter</span><span class="p">[</span><span class="s1">'well'</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(1, 5418)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>There were <strong>78,157</strong> unique tokens! It’s interesting seeing that some of them are typos, or just have additional characters attached to the word, such as <code>well@@</code> instead of <code>well</code>
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have our token frequency counter, we can go ahead and make our vocab!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sorted_counter</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">token_counter</span><span class="o">.</span><span class="n">most_common</span><span class="p">())</span>

<span class="c1"># Create vocab containing tokens with a minimum frequency of 20</span>
<span class="n">my_vocab</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">vocab</span><span class="p">(</span><span class="n">sorted_counter</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># Add the unknown token, and use this by default for unknown words</span>
<span class="n">unk_token</span> <span class="o">=</span> <span class="s1">'&lt;unk&gt;'</span>
<span class="n">my_vocab</span><span class="o">.</span><span class="n">insert_token</span><span class="p">(</span><span class="n">unk_token</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">my_vocab</span><span class="o">.</span><span class="n">set_default_index</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Add the pad token</span>
<span class="n">pad_token</span> <span class="o">=</span> <span class="s1">'&lt;pad&gt;'</span>
<span class="n">my_vocab</span><span class="o">.</span><span class="n">insert_token</span><span class="p">(</span><span class="n">pad_token</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Show vocab size, and examples of tokens</span>
<span class="nb">len</span><span class="p">(</span><span class="n">my_vocab</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()),</span> <span class="n">my_vocab</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()[:</span><span class="mi">25</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(7591,
 ['&lt;unk&gt;',
  '&lt;pad&gt;',
  '.',
  'the',
  ',',
  'i',
  'and',
  'a',
  'to',
  'it',
  'of',
  "'",
  'this',
  'is',
  'in',
  'that',
  'for',
  'was',
  'you',
  '!',
  'book',
  's',
  'but',
  'with',
  'not'])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>We’ll be using <code>&lt;unk&gt;</code> as our default token for tokens that are out of our vocab!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>Notice how we passed in a <code>min_freq</code> argument. This ensures that the vocab only includes high frequency tokens. We wouldn’t want to include tokens that only occur once/rarely. This brought our vocab count down from <strong>75,889</strong> to <strong>7,591</strong>! A <strong>~90% reduction</strong>!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Rather than starting from scratch, we can preload GloVe embeddings into our vocabulary!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">glove</span> <span class="o">=</span> <span class="n">torchtext</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">GloVe</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">'6B'</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">glove</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([400000, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we're using GloVe vectors for <em>transfer learning</em> (by preloading our embedding), let's take a look at how many tokens can be successfully transferred from GloVe into our own vocab. Each token will have an embedding (vector) of size 100. This results in an embedding of size <strong>7591x100</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span> <span class="o">=</span> <span class="n">glove</span><span class="o">.</span><span class="n">get_vecs_by_tokens</span><span class="p">(</span><span class="n">my_vocab</span><span class="o">.</span><span class="n">get_itos</span><span class="p">())</span>
<span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([7591, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By default, tokens that aren't able to transfer from GloVe into our own dataset get initialized with a vector of 0's. We can use this to count how many tokens were successfully preloaded!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tot_transferred</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">v</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)):</span>
        <span class="n">tot_transferred</span> <span class="o">+=</span> <span class="mi">1</span>
        
<span class="n">tot_transferred</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">my_vocab</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(7517, 7591)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>Not bad, 7517 out of our 7591 tokens were successfully transferred!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">my_vocab</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()[</span><span class="mi">3</span><span class="p">],</span> <span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('the',
 tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,
         -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,
          0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,
          0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,
          0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,
         -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,
         -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,
          0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,
          1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,
         -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,
          0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,
          0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,
         -0.5203, -0.1459,  0.8278,  0.2706]))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">my_vocab</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()[</span><span class="mi">6555</span><span class="p">],</span> <span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="mi">6555</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>('eargels',
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0.]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Note that the vector for index 3 corresponds to the word/token <code>the</code> and it has non-zero values in the vector since we were able to preload it from GloVe! Index 6559 corresponds to the word <code>eargels</code> and it’s all zeros, which means that it wasn’t part of Glove’s vocab and therefore couldn’t transfer it’s embedding to our vocab!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>There were 400k tokens/words in GloVe, and <code>stardust</code> wasn’t one of them :O
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-error">
    <svg class="octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path></svg>
    <strong>Warning: </strong>Initializing the embeddings to 0 isn’t the best idea. If we use these embeddings for transfer learning to our embedding layer, then <strong>all</strong> new tokens not found in GloVe will have an indentical vector representation of all 0s. I found the model to be harder to train because of this, and I concluded that it’s due to these 0s being multiplied in our model’s forward pass which creates more 0s, and possibly cause some gradients to be 0, making it much more difficult to learn these new embeddings.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Rather than initializing new token embeddings to 0’s, let’s use <code>torch.randn</code> to create some diversity between the different token embeddings that weren’t preloaded with GloVe!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">if</span> <span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)):</span>
        <span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's use our vocab to <em>numericalize</em> our tokens!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_text</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sample_text</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">))</span>
<span class="n">tokens</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#81) ['this','sound','track','was','beautiful','!','it','paints','the','senery'...]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use our vocab to convert each token to it's numeric representation one-by-one using a list comprehension!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">my_vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
<span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">numericalized_tokens</span><span class="p">)</span>
<span class="n">numericalized_tokens</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([  12,  222,  505,   17,  405,   19,    9, 5931,    3,    0,   14,   74,
         424,   34,   85,    5,   49, 1490,    9,   78,    8,  120,   70,  704,
           0,    2,  255,  133,   19,    5,   27,  545,    3,  255,    0, 2380,
          22,   55,   10,   33,   10,    3,  801,    5,   27,  136,  545,    9,
          53,    3,  107,  133,   19,    9,    0,  274,   45, 3843,    0,    6,
         433,    7,    0, 1368,   23,    0, 3306,    6, 3844,    0,    2,    9,
          49, 4234,  183,   70, 2260,    8,  344,   19,    0])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">my_vocab</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()[</span><span class="n">num</span><span class="p">]</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">numericalized_tokens</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'this sound track was beautiful ! it paints the &lt;unk&gt; in your mind so well i would recomend it even to people who hate &lt;unk&gt; . game music ! i have played the game &lt;unk&gt; cross but out of all of the games i have ever played it has the best music ! it &lt;unk&gt; away from crude &lt;unk&gt; and takes a &lt;unk&gt; step with &lt;unk&gt; guitars and soulful &lt;unk&gt; . it would impress anyone who cares to listen ! &lt;unk&gt;'</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">numericalized_tokens</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([81])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Notice how uncommon words have value <code>0</code> in their numericalized form! This corresponds to the <code>&lt;unk&gt;</code> token.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This example has 81 tokens, but other examples may have more or less. It'll be a good idea to cap the number of tokens + pad the amount of tokens to a desired number of tokens. This will be needed in order to batch our samples together, as they can't vary in size!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_tokens</span> <span class="o">=</span> <span class="mi">128</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">my_vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">numericalized_tokens</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_tokens</span><span class="p">:</span>
    <span class="n">numericalized_tokens</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_tokens</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">numericalized_tokens</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="n">numericalized_tokens</span><span class="p">[:</span><span class="n">max_tokens</span><span class="p">]</span>

<span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">numericalized_tokens</span><span class="p">)</span>
<span class="n">numericalized_tokens</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([  12,  222,  505,   17,  405,   19,    9, 5931,    3,    0,   14,   74,
         424,   34,   85,    5,   49, 1490,    9,   78,    8,  120,   70,  704,
           0,    2,  255,  133,   19,    5,   27,  545,    3,  255,    0, 2380,
          22,   55,   10,   33,   10,    3,  801,    5,   27,  136,  545,    9,
          53,    3,  107,  133,   19,    9,    0,  274,   45, 3843,    0,    6,
         433,    7,    0, 1368,   23,    0, 3306,    6, 3844,    0,    2,    9,
          49, 4234,  183,   70, 2260,    8,  344,   19,    0,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>Remember that the pad token is represented by a 1 in it’s numericalized form!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="3.-Dataset-&amp;-DataLoaders-[PyTorch-&amp;-fastai]">
<a class="anchor" href="#3.-Dataset-&amp;-DataLoaders-%5BPyTorch-&amp;-fastai%5D" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Dataset &amp; DataLoaders [PyTorch &amp; fastai]<a class="anchor-link" href="#3.-Dataset-&amp;-DataLoaders-%5BPyTorch-&amp;-fastai%5D"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we have everything we need to tokenize and numericalize our input, let's go ahead and make a simple Dataset class</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">Simple_Dataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">"basic_english"</span><span class="p">)</span>
        
        <span class="c1"># label 1 is negative sentiment and label 2 is positive sentiment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
        
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">numericalized_tokens</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()[</span><span class="n">num</span><span class="p">]</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="n">numericalized_tokens</span><span class="p">])</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">label</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_map</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">my_vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">numericalized_tokens</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_tokens</span><span class="p">:</span>
            <span class="n">numericalized_tokens</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_tokens</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">numericalized_tokens</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="n">numericalized_tokens</span><span class="p">[:</span><span class="n">max_tokens</span><span class="p">]</span>

        <span class="n">numericalized_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">numericalized_tokens</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">numericalized_tokens</span><span class="p">,</span> <span class="n">label</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">Simple_Dataset</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">my_vocab</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">Simple_Dataset</span><span class="p">(</span><span class="n">valid_df</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">my_vocab</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(40000, 2000)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>40k training samples and 2k validation samples. Feel free to try this on a larger dataset!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokens</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">label</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([  12,  222,  505,   17,  405,   19,    9, 5931,    3,    0,   14,   74,
          424,   34,   85,    5,   49, 1490,    9,   78,    8,  120,   70,  704,
            0,    2,  255,  133,   19,    5,   27,  545,    3,  255,    0, 2380,
           22,   55,   10,   33,   10,    3,  801,    5,   27,  136,  545,    9,
           53,    3,  107,  133,   19,    9,    0,  274,   45, 3843,    0,    6,
          433,    7,    0, 1368,   23,    0, 3306,    6, 3844,    0,    2,    9,
           49, 4234,  183,   70, 2260,    8,  344,   19,    0,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
            1,    1,    1,    1,    1,    1,    1,    1]),
 tensor(1))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'this sound track was beautiful ! it paints the &lt;unk&gt; in your mind so well i would recomend it even to people who hate &lt;unk&gt; . game music ! i have played the game &lt;unk&gt; cross but out of all of the games i have ever played it has the best music ! it &lt;unk&gt; away from crude &lt;unk&gt; and takes a &lt;unk&gt; step with &lt;unk&gt; guitars and soulful &lt;unk&gt; . it would impress anyone who cares to listen ! &lt;unk&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt; &lt;pad&gt;'</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can now create our fastai DataLoaders <code>dls</code> to use for later!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span>
<span class="n">dls</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;fastai.data.core.DataLoaders at 0x7f19b2962130&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="4.-Model-[PyTorch]">
<a class="anchor" href="#4.-Model-%5BPyTorch%5D" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Model [PyTorch]<a class="anchor-link" href="#4.-Model-%5BPyTorch%5D"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now to the model creation section! Our PyTorch model will contain the following layers/components:</p>
<ul>
<li>
<strong>Embedding Layer</strong>: converts numericalized tokens into their embedding representation</li>
<li>
<strong>LSTM</strong>: processes the sequence of embeddings</li>
<li>
<strong>Head</strong>: Takes final feature vector of LSTM for classification prediction</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_size</span> <span class="o">=</span> <span class="n">vocab</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_size</span><span class="p">,</span> <span class="n">_weight</span><span class="o">=</span><span class="n">vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">emb_size</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">batch_first</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">):</span>

        <span class="n">token_embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        
        <span class="n">outputs</span><span class="p">,</span> <span class="p">(</span><span class="n">h_n</span><span class="p">,</span> <span class="n">c_n</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">token_embs</span><span class="p">)</span>
        
        <span class="c1"># Assuming a batch size of 32, h_n will have a shape of:</span>
        
        <span class="c1"># shape = 2, 32, 64</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">h_n</span>
        <span class="c1"># shape = 32, 2, 64</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># shape = 32, 128</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">logits</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-error">
    <svg class="octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z"></path></svg>
    <strong>Warning: </strong>If you forget the <code>_weight=vocab.vectors</code> in the PyTorch <code>nn.Embedding()</code> layer creation function, you’ll simply initialize your embedding with all random numbers &amp; nothing will transfer from GloVe! Feel free to comment out that bit and see how the performance drops due to the lack of transfer learning!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">my_vocab</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model(
  (emb): Embedding(7591, 100)
  (lstm): LSTM(100, 64, num_layers=2, batch_first=True)
  (head): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU()
    (2): Linear(in_features=64, out_features=2, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's double check that some of our embeddings were successfully loaded from the domain-overlapping tokens from GloVe. Below is our preloaded embedding matrix!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">embedding_matrix</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">embedding_matrix</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([[-0.4916,  1.7088,  0.7117,  ...,  0.1416,  0.9630,  0.4806],
        [ 0.4609, -0.7693,  0.0846,  ..., -0.5245,  0.7817, -0.2093],
        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],
        ...,
        [ 0.2659,  0.1006, -0.1915,  ...,  0.4461,  0.2491,  0.0310],
        [ 0.2600,  0.0077,  0.6122,  ...,  0.1818, -0.2181,  0.0772],
        [-0.2763, -0.2575, -0.1396,  ...,  0.1692, -0.1993,  0.4247]],
       requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Index <code>3</code> corresponds to <code>'the'</code>:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">my_vocab</span><span class="o">.</span><span class="n">vectors</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">embedding_matrix</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>Our pre-loaded embedding parameters for index 3 matches up with our vocab vectors, nice!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">total_params</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">total_params</span> <span class="o">+=</span> <span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
<span class="n">total_params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>843262</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>~865k parameters!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's go ahead and make sure we can do a forward pass through our model, our loss function will be <code>CrossEntropyLoss</code> as it's a classification task.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batched_data</span><span class="p">,</span> <span class="n">batched_labels</span> <span class="o">=</span> <span class="n">train_dl</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batched_data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">batched_labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([32, 128]) torch.Size([32])
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batched_data</span><span class="p">)</span>
<span class="n">logits</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([32, 2])</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">batched_labels</span><span class="p">)</span>
<span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(0.7026)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sweet!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="5.-Training/Fitting-[fastai]">
<a class="anchor" href="#5.-Training/Fitting-%5Bfastai%5D" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Training/Fitting [fastai]<a class="anchor-link" href="#5.-Training/Fitting-%5Bfastai%5D"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Time to use fastai to contain our <code>dls</code>, <code>model</code>, and <code>metrics</code> &amp; assist with training using certain best practices!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
<span class="n">learn</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;fastai.learner.Learner at 0x7f5c4113b3d0&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=tensor(0.0052))</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">3e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.426767</td>
      <td>0.401867</td>
      <td>0.826000</td>
      <td>01:52</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.282645</td>
      <td>0.295986</td>
      <td>0.874500</td>
      <td>02:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.226144</td>
      <td>0.283338</td>
      <td>0.878000</td>
      <td>02:46</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.145605</td>
      <td>0.325866</td>
      <td>0.875500</td>
      <td>02:43</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.125661</td>
      <td>0.348530</td>
      <td>0.875500</td>
      <td>02:38</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Nice, but this model may have started overfitting near the end of training as it doesn't have any dropout, weight-decay, or other forms of regularization!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="6.-Using-a-Language-Model-via-AWD-LSTM-[fastai]">
<a class="anchor" href="#6.-Using-a-Language-Model-via-AWD-LSTM-%5Bfastai%5D" aria-hidden="true"><span class="octicon octicon-link"></span></a>6. Using a Language Model via AWD-LSTM [fastai]<a class="anchor-link" href="#6.-Using-a-Language-Model-via-AWD-LSTM-%5Bfastai%5D"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using a pretrained language model for downstream tasks is a popular and efficient technique also! Fine-tuning the language model first is even better, as shown in <a href="https://github.com/fastai/fastbook/blob/master/10_nlp.ipynb">chapter 10 from fastbook</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's a quick example of training a model with this dataset using fastai!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we'll need to create our vocab as we did before!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fastai_vocab</span> <span class="o">=</span> <span class="n">make_vocab</span><span class="p">(</span><span class="n">token_counter</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To continue using the same subset dataframes, we'll combine both the <code>train_df</code> and <code>valid_df</code> into <code>combined_df</code>, then let fastai split at index 40k by using the <code>splitter</code> argument in the <a href="https://docs.fast.ai/tutorial.datablock.html">DataBlocks API</a>!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">combined_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train_df</span><span class="p">,</span> <span class="n">valid_df</span><span class="p">])</span>
<span class="n">combined_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>title</th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>Stuning even for the non-gamer</td>
      <td>This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>The best soundtrack ever to anything.</td>
      <td>I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>Amazing!</td>
      <td>This soundtrack is my favorite music of all time, hands down. The intense sadness of "Prisoners of Fate" (which means all the more if you've played the game) and the hope in "A Distant Promise" and "Girl who Stole the Star" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like "Chrono Cross ~ Time's Scar~", "Time of the Dreamwatch", and "Chronomantique" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears s...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2</td>
      <td>Excellent Soundtrack</td>
      <td>I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Uns...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>Remember, Pull Your Jaw Off The Floor After Hearing it</td>
      <td>If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">combined_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>42000</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">amazon_polarity</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="p">(</span><span class="n">TextBlock</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">'text'</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">fastai_vocab</span><span class="p">),</span>
                                    <span class="n">CategoryBlock</span><span class="p">),</span>
                            <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'text'</span><span class="p">),</span>
                            <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s1">'label'</span><span class="p">),</span>
                            <span class="n">splitter</span><span class="o">=</span><span class="n">IndexSplitter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">40000</span><span class="p">,</span> <span class="mi">42000</span><span class="p">)))</span>

<span class="c1"># Passing a custom DataFrame in and splitting by the index!</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">amazon_polarity</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">combined_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">train_ds</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">valid_ds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(40000, 2000)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>Looks good! We still have our 40k training samples and 2k validation samples :)
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">train</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">valid</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(1250, 63)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">show_batch</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxup buyer xxup beware ! ! ! yes xxup the xxup diapers xxup are xxup good xxup but i xxup received xxup the xxup diapers xxup with xxup stains xxup they xxup look xxup like xxup dna xxup stains . xxup so i xxup call xxup the xxup company xxup and xxup they xxup instruct xxup me xxup to xxup xxunk xxup them xxup away xxup all 200 xxup diapers xxup wow . xxup so i xxup wait xxup in xxup the xxup mail xxup for xxup some xxup coupons xxup they xxup are xxup supposed xxup to xxup send xxup me xxup and xxup turns xxup out i xxup have xxup to xxup spend xxup more xxup money xxup in xxup order xxup to xxup get xxup the xxup diapers i xxup had xxup already xxup paid xxup for . xxup so i xxup call xxup company xxup</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxup this xxup is xxup one xxup of xxup the xxup stupidest , xxup silly , xxup totally xxup xxunk xxup movies i xxup have xxup ever xxup seen . i xxup have xxup always xxup loved xxunk disasters xxup in xxup nature xxup movies xxunk . i xxup was xxup not xxup disapointed . xxup this xxup was xxup truly a xxup horrific xxup catastrophe . xxup the xxup best xxup part xxup of xxup the xxup movie xxup was xxunk xxunk was xxunk xxunk xxup was xxunk xxunk i xxup am xxup getting xxup there xxunk xxunk xxunk xxunk xxunk xxup the xxup story xxup had xxup no xxup meaning . xxup xxunk xxup xxunk xxup should xxup sell xxup xxunk xxup tickets xxup the xxup next xxup time xxup she xxup needs xxup money . xxup her xxup talents xxup were xxup totally xxup wasted .</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xxbos xxup if xxup you xxup take a xxup look xxup at xxup the 1 xxup star xxup review , i xxup am xxup the xxup one xxup that xxup left a xxup comment xxup in xxup favor , xxup but xxup wondering xxup why xxup they xxup left xxup only xxup one xxup star . xxup it xxup had xxup to xxup be a xxup mistake xxup because xxup she xxup gave xxup it a xxunk haunting xxunk xxup review , xxup if xxup not xxup too xxup short . xxup the xxup tune xxunk ' estate ' xxup is xxup with xxup out a xxup doubt a xxup five xxup star xxup tune . xxup in xxup fact , xxup one xxup of xxup the xxup most xxup beautiful xxup jazz xxup vocal xxup numbers i xxup can xxup remember xxup hearing . xxup however , xxup the</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>xxbos xxmaj some may ask why , but i say bring on a collection like this . xxmaj why not ? xxmaj this is xxunk music . xxmaj is it techno or electronica , who cares , just dance and enjoy . xxmaj my biggest complaints are , why six tracks from xxunk homework xxunk , and only three from xxunk discovery xxunk ? xxmaj also , some of these songs like xxunk rollin ' &amp; xxmaj xxunk ' xxunk and xxunk robot xxmaj rock xxunk are xxup so repetitive ( i know that xxunk the point ) , they get old by the three minute mark . xxmaj yet , other tracks like xxunk around xxmaj the xxmaj world xxunk and xxunk one xxmaj more xxmaj time xxunk are perfection , hence the classics they are . xxmaj one other disappointment xxunk xxunk the hell is xxunk digital xxmaj</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>xxbos i absolutely loved this xxup cd and i think everyone in america should own a copy ( or maybe xxunk and my friends have been behind clay since the beginning ( well almost the beginning ) and were so excited when he got back on in the wild card show . i was so excited when this xxup cd came out . i love every song on this xxup cd and listen to it 24 / 7 ( more like 25 / xxunk ! xxmaj this is by far the best xxup cd i xxunk bought in years . xxmaj it was worth every penny . i ca nt wait for clays next xxup cd ! xxmaj people of all ages can enjoy clay xxunk music . xxmaj some of my favorites are xxmaj invisible , i will carry you , the way , when you say you love</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>xxbos xxmaj this is one of the worst books in the world xxrep 3 - in my humble opinion ! xxup ok , xxmaj i xxunk in the minority . xxmaj most of the reviewers xxup loved the book . i think this book is a waste of beautiful words ! xxmaj yes , xxmaj conrad had a beautiful xxmaj english vocabulary . xxmaj but , the xxunk story xxunk is xxunk xxunk xxunk with so many words you xxunk tire of it after awhile . xxup ok , try the book , but now , at least , you xxunk xxunk feel as i did , xxunk what xxunk wrong with xxup me that i do xxunk like this book . xxunk xxmaj you xxunk xxunk feel xxunk alone xxunk in your reaction . i think xxunk heart of xxmaj darkness xxunk is a much better book . xxmaj</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>xxbos xxmaj first , xxmaj i xxunk read all the books in the series and enjoyed them . xxmaj okay xxunk plains of xxmaj passage xxunk was a boring read but not too bad . xxmaj in xxunk the xxmaj shelters of xxmaj stone xxunk xxmaj jean xxmaj auel makes xxmaj ayla out to be some kind of super - woman , who invented open heart surgery to figuring out xxunk where babies come from . xxunk xxunk ? xxmaj it xxunk gone too far . i think the long wait between books as made me lose interest . xxmaj either that or xxmaj ms . xxmaj auel ca xxunk write xxmaj ayla anymore . xxmaj she lost her momentum . xxmaj at the beginning it was fun to see xxmaj ayla invent all this stuff , but the fun is gone . i suppose this can happen with a</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>xxbos i am like you at this very moment , you do xxunk want to believe the reviews you are reading . . xxunk they are xxup xxunk read all the reviews here before i purchased xxunk anne of xxmaj green gables - the xxmaj continuing xxmaj story xxunk . i did xxunk want to believe what i read , because this is xxmaj anne of xxmaj green xxmaj gables , the last two videos were xxup great , why would xxunk this one be too ? xxup it xxup is xxup not xxup worth xxup it ! , please trust me on xxunk beginning part of the movie is really nice to watch . . xxunk the war begins , xxmaj gilbert leaves and xxmaj anne leaves to go find xxmaj gilbert . xxmaj and i am waiting and waiting for xxmaj anne to come back to xxmaj avonlea</td>
      <td>1</td>
    </tr>
    <tr>
      <th>8</th>
      <td>xxbos xxmaj chris xxunk . xxmaj chris was my next door neighbor on 13th floor of xxmaj xxunk hall at xxmaj xxunk xxmaj state xxmaj university in 1977 . xxmaj chris xxunk favorite album was xxunk smoke xxmaj from a xxmaj distant xxmaj fire xxunk from the xxmaj sandford and xxmaj townsend xxmaj band . i listened to it so much when i was in college in xxmaj chris xxunk room that i learned each one of the ten songs by heart . xxmaj try listening to the ending fugue of xxunk squire xxmaj james xxunk at 3 xxunk sometime when you xxunk been up all night partying - it was enough to make you rethink your xxunk youth . xxmaj the lyrics of this album are sometimes repetitive and simplistic . xxmaj for example , count the number of times the themes of smoke , fire , burning ,</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Take a close look at the samples above! We can see that we’re not using a simple tokenizer that just separates on spaces anymore! This tokenizer has lots of additional special tokens and special rules to help with better feature/token engeineering! (e.g. <code>xxbos</code> -&gt; beginning of a text, and <code>xxmaj</code> -&gt; next word capitalized) More can be found here in <a href="https://github.com/fastai/fastbook/blob/master/10_nlp.ipynb">chapter 10 from fastbook</a>
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>We’ll be using the <a href="https://docs.fast.ai/text.models.awdlstm.html#AWD_LSTM">AWD-LSTM</a> language model as our pretrained model to finetune!
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=tensor(0.0036))</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAz3klEQVR4nO3dd3yUZbbA8d+ZyUwaSYAQQgkl9CbSBARBFAVlRVBYRBErKmtde9viqnvvFtu1rWVVdFdFREFU1roIKEoPXSDUhEB67+W5f8wkhjAJCWTyziTn+/nkY97yzHsmhjl5uhhjUEoppWqyWR2AUkop36QJQimllEeaIJRSSnmkCUIppZRHmiCUUkp5pAlCKaWURwFWB9CY2rVrZ7p37251GEop5Tc2btyYZoyJ8nStWSWI7t27s2HDBqvDUEopvyEih2q7pk1MSimlPNIEoZRSyiNNEEoppTzSBKGUUsojTRBKKaU80gShlFLKI00QSinlx7YfyWb13lSvvLYmCKWU8mP//ukQ9yza4pXX1gShlFJ+LDmniOjwQK+8tiYIpZTyY8k5xUSHBXnltTVBKKWUH0vJLaK91iCUUkpVV1peQXp+Ce21BqGUUqq6tLxijIHocE0QXlNYUk5hSbnVYSilVIMk5xQDaCe1N535+Ff837d7rQ5DKaUaJDmnCNAahFeFOu0UlJRZHYZSSjVIijtBtA/TGoTXhDgDyC/WJiallH9JyS3GJhDZShOE14Q47RSWag1CKeVfknOKiAoLxG4Tr7y+JgggJFBrEEop/5OcU+y1/gfQBAFoH4RSyj8l5xR5bQ4EaIIAXE1MWoNQSvmblNxir82iBk0QgKuTurBUE4RSyn+UlFWQkV/itXWYQBMEAKGBdvKLtYlJKeU/UvO8O0kONEEAEOwIoEBnUiul/Ii3J8mBlxOEiFwkIrtFJF5EHvJwvY2ILBGRrSKyTkQG1bdsYwoNdHVSG2O8+RillGo0lZPkorw0SQ68mCBExA68BFwMDACuFJEBNW57BIgzxgwGrgH+rwFlG02IM4AKA8VlFd56hFJKNaqU3MomJv+sQYwE4o0x+40xJcBCYFqNewYA3wIYY34GuotIdD3LNpoQpx1A+yGUUn4jOacIu02IDHV67RneTBCdgYRqx4nuc9VtAS4HEJGRQDcgpp5lcZe7WUQ2iMiG1NRT27i7MkFoP4RSyl8k5xTTPiwQm5dmUYN3E4SnqGs28v8FaCMiccAdwGagrJ5lXSeNec0YM8IYMyIqKuqUAg0NDAA0QSil/EdyThHtvdi8BBDgxddOBLpUO44BkqrfYIzJAa4HEBEBDri/Qk5WtjEFVzYx6WxqpZSfSMkppmtkiFef4c0axHqgt4jEiogTmA0sq36DiLR2XwOYB6xyJ42Tlm1MoU5XntRNg5RS/iIlt8ircyDAizUIY0yZiNwOfAnYgTeNMTtEZL77+itAf+AdESkHdgI31lXWW7FqJ7VSyp8Ul5WTWVDq1VnU4N0mJowxy4HlNc69Uu37H4He9S3rLdpJrZTyJyk53h/iCjqTGtBOaqWUf0nJde8k5+UmJk0QVK9BaBOTUsr3JbtrEN5c6hs0QQCumdSALvmtlPILKVXrMGkNwuvsNiEwwEaBbjuqlPIDybnFOOxCmxDvzaIGTRBVQgMDKNAahFLKD1TuJOfNWdSgCaJKsMOuE+WUUn4hJce7O8lV0gThFhpo14lySim/4KpBaIJoMiHOAPI1QSil/EBKbrHX50CAJogqIU47BTqTWinl4zLzS8guLCWmTbDXn6UJwi3EqduOKqV8X3xqHgC9o8O8/ixNEG6V244qpZQv25vsThDtW3n9WZog3EKcdu2DUEr5vL0puQQ77HSK0CamJhPiDNBRTEopnxefkkev9q28PgcCNEFUCXW65kEY43HjOqWU8gl7k/OapHkJNEFUCXYGYAwUlVZYHYpSSnmUW1TKsZwiekVrgmhSoYG6oqtSyrfFp1R2UHt/BBNogqhSuaKrDnVVSvmqvSlNN4IJNEFUqdp2VGsQSikfFZ+ShzPARpe2IU3yPE0QbrrtqFLK1+1NzqVnVCvsTTCCCTRBVKnadlSX/FZK+ai9KU03ggk0QVQJdmgTk1LKdxWUlJGYWagJwgqVNQidLKeU8kX7UvIB6N1EQ1xBE0SVUO2kVkr5sL0puQD0aqIhrqAJokpwZSe19kEopXzQ3pQ8HHahW2TTjGACTRBVdB6EUsqX7U3OI7ZdKA57031sa4Jws9uEIIdNZ1IrpXxSfEpuk82grqQJohrXtqOaIJRSvqWotJzDGQX0asIRTKAJ4jghTrs2MSmlfM7+1HwqTNOOYAJNEMcJdQZoJ7VSyufsc28zqjUICwW794RQSilfkpJbDECH8KAmfa5XE4SIXCQiu0UkXkQe8nA9QkQ+FZEtIrJDRK6vdu2giGwTkTgR2eDNOCu59qXWGoRSyrdk5BcTYBPCgxxN+twAb72wiNiBl4ALgURgvYgsM8bsrHbbbcBOY8xUEYkCdovIu8aYEvf184wxad6KsaYQZwAZ+YVN9TillKqX9LwS2oY6m2Sb0eq8WYMYCcQbY/a7P/AXAtNq3GOAMBERoBWQAVjWxuPqpNYmJqWUb0nLKyGyVWCTP9ebCaIzkFDtONF9rroXgf5AErANuMsYU7nnpwG+EpGNInJzbQ8RkZtFZIOIbEhNTT2tgEOcAeRrJ7VSysek5xfTrpWzyZ/rzQThqS5kahxPBuKATsAQ4EURCXdfG2uMGQZcDNwmIuM9PcQY85oxZoQxZkRUVNRpBRzqtFOoNQillI+pbGJqat5MEIlAl2rHMbhqCtVdD3xsXOKBA0A/AGNMkvu/KcASXE1WXhXitFNQWk5FRc08ppRS1snILyEytHk1Ma0HeotIrIg4gdnAshr3HAYmAohINNAX2C8ioSIS5j4fCkwCtnsxVgBCAgMwBorKtJlJKeUbikrLySsuI9KCJiavjWIyxpSJyO3Al4AdeNMYs0NE5ruvvwI8ASwQkW24mqQeNMakiUgPYImr75oA4D1jzBfeirVSaLVtRysX71NKKSul57sGdVrRB+HVT0FjzHJgeY1zr1T7PglX7aBmuf3Amd6MzZNgZ7VtR5t2wqJSSnmUnueaJNfcmpj8jm4apJTyNel5rhqEFU1MmiCqCQnUPSGUUr6lsolJaxAWC6nqg9AahFLKN1Q1MWkNwlqVCUInyymlfEV6fglBDlvV51NT0gRRTai7k7qwVGsQSinfkJZXTGRoIO5RnU1KE0Q1IYFag1BK+Zb0vBJLhriCJojjVM590D4IpZSvyMi3ZpkN0ARxnGDHLxPllFLKF6TnFVuykitogjiO3SYEO3TTIKWUbzDGkJZfYskIJtAEcYIQp538Ym1iUkpZL6+4jJKyCtpZMAcCNEGcICTQTqHWIJRSPsDKWdSgCeIEoc4AXWpDKeUTqmZRax+Ebwh2ah+EUso3/LJQn9YgfEKoM0AThFLKJ/xSg9AE4RO0k1op5SsqaxA6D8JHhGgTk1LKR6TllRAWFEBgQNOvwwSaIE4QEhigM6mVUj4hI7+EdhZ1UIMmiBNEhwWRlldCUanWIpRS1krPL7aseQk0QZyge7sQAA5nFFgciVKqpUvPK7FsBBNogjhB98hQAA6m5VsciVKqpUvLK7FsDgRogjhBVYJI1wShlLJORYUhI7/YsqW+QRPECSJCHLQJcXAgTZuYlFLWySospcJYN0kONEF41L1dKIe0BqGUslBGfuVe1NrE5FNiI0O1D0IpZam0yoX6tAbhW7pFhpKUXaRDXZVSlvllJVetQfgUHeqqlLJaelUTk4/XIEQkVERs7u/7iMilIuLwbmjWqRzJdECbmZRSFknLK0EE2oT4eIIAVgFBItIZ+Ba4HljgraCs1r2dK0FoR7VSyioZ+cW0DXFit4llMdQ3QYgxpgC4HHjBGHMZMMB7YVkrIthB21CnDnVVSlkmPa/E0mU2oAEJQkTOBuYAn7vPBXgnJN/QLTJERzIppSyTnu8/CeK3wMPAEmPMDhHpAaw4WSERuUhEdotIvIg85OF6hIh8KiJbRGSHiFxf37LeFhupcyGUUtbJzC+xtP8B6pkgjDErjTGXGmP+6u6sTjPG3FlXGRGxAy8BF+NqjrpSRGo2S90G7DTGnAlMAJ4WEWc9y3qVDnVVSlkps6CUNqHWjgWq7yim90QkXERCgZ3AbhG5/yTFRgLxxpj9xpgSYCEwrcY9BggTEQFaARlAWT3LelXlUNdD6doPoZRqWsYYsgpKaO0PNQhggDEmB5gOLAe6AnNPUqYzkFDtONF9rroXgf5AErANuMsYU1HPsl4V204X7VNKWSOvuIyyCkObED+oQQAO97yH6cAnxphSXH/918XT2KyaZSYDcUAnYAjwooiE17Os6yEiN4vIBhHZkJqaepKQ6q+bLvutlLJIVkEpgN/UIF4FDgKhwCoR6QbknKRMItCl2nEMrppCddcDHxuXeOAA0K+eZQEwxrxmjBlhjBkRFRVVz7dzcpVDXbUGoZRqapkFrmU2/KWT+nljTGdjzBT3h/kh4LyTFFsP9BaRWBFxArOBZTXuOQxMBBCRaKAvsL+eZb3ONdRV+yCUUk0r012D8IsmJvdw1Gcqm3JE5GlctYlaGWPKgNuBL4FdwCL3ENn5IjLffdsTwBgR2YZrhvaDxpi02sqe0js8DbGRoVqDUEo1uSx3DcLqJqb6TnZ7E9gOzHIfzwXewjWzulbGmOW4OrWrn3ul2vdJwKT6lm1q3duF8vHmIxSVlhPksFsZilKqBcnMr2xisrYGUd8E0dMYM6Pa8Z9EJM4L8fiUbpG/DHXt2yHM4miUUi1FZRNTRLAfNDEBhSJyTuWBiIwFCr0Tku/o1b4VAHEJmRZHopRqSbIKSggPCiDAbu2ODPWtQcwH3hGRCPdxJnCtd0LyHQM6htMzKpT31iVwxVldrQ5H1cEYw5c7jvHWDwfpHd2Kuyb2ISrMuo1WlDodrlnU1vY/QP1HMW1xL4cxGBhsjBkKnO/VyHyAiDB3dDe2JGSxNTHL6nCUB8YYVvycwtQXv2f+vzeRmFnIwnUJnPfUd7y0Il6XSlF+KdMHZlFDA3eUM8bkuGdUA9zjhXh8zuXDYwh22Pn3T4esDkXV8POxHOb8cy3XL1hPdmEpT//6TFbeP4Ev7x7PmJ6R/P3L3fzq+dVku9tzlfIXWQWllndQw+ltOWrdLhZNKDzIwfShnfkkLkk/aHxEVkEJv1+6nSn/t5odSTn86dKBfHvPBGYMjyHAbqNnVCteu2YEC64/i8MZBdy5cDPlFSeb+K+U78gssH4lVzi9BNFi/sVdPborxWUVfLgxweN1YwxvfH+ABN3D2uuMMVy/YD3vrTvM3NHd+O6+CVw7pjvOgBN/lSf0bc/j0waxck8qf/vyZwuiVerUZBWU0toHahB1dlKLSC6eE4EAwV6JyAcN7BTB8G5teHftYW4YG4utxhaAO4/m8MRnO0nIKOCxSwdaFGXLsHpvGpsPZ/HnywYxZ1S3k95/5ciu7EzK4dWV+xnQMZzRPSL5IT6NdQcyGNatDbNGdDnpayjVlErKKsgrLvOJGkSdCcIYo4P/3eaO7sZvP4jjh31pjOt9/JpP/92VAsCafWlWhNaivPjfeDpGBDFzeEy9y/xh6gB2J+dy9wdxVLY0BQbYWLg+gWPZRdxxfi9cK84rZb2sQt+YJAen18TUolx8Rgfahjo9dlZ/87MrQexJziM1t7ipQ2sx1u5PZ93BDG4Z34PAgPrPbHfYbbw8ZxizRnTh0Sn9+fzOc9j+p8lcPqwzz3y9h79+sRtjWkyLqfJxvrKSK2iCqLfAADszhnXm210ppOX9kgRSc4vZkpDFBf2jAa1FABzJKuT1VfvJKWrcTv0XV8TTrpWT2SMbPielXatA/jJjMDeN78HAThE47Daemnkmc0Z15ZWV+/jjsh1UaEe28gG/LLOhCcKvzBrRhbIKw9LNR6rOrXDXHu6a2JvwoADWxKfXWr6iwnDpi98z/ImvmfXqjzyyZBufbz3q9bibUnZhKde+uY4/L9/FxKdX8vnWo43y1/nmw5ms3pvGTeN6NNq6WDab8OT0Qdw0LpZ3fjzEfR9uobS8olFeW6lTlVlVg9AmJr/SOzqMoV1b88H6hKoPvW9/TqZjRBCDOrs6QNfsr70G8d2eFLYmZnNGTAQVFYbPtx7ltvc28cH6w031FhosJaeI9Lz6NZuVlVdw+3ubOJSez5PTB9E+LJDb3tvEDQvWsyY+7bhJa4Ul5Xy7K5kXvt3L7mO5J7xWRYXhaHYhB9Py2ZOcy3Pf7KV1iIM5o0/eMd0QIsIjU/pz36Q+fLz5CL/596aqOI0xxKfkcriWbWcTMgrYkZRNck4RpeUVpOYW897aw1z75jr6/f4/vLtW586ohqtcydUXZlLXd6kN5TZrRBce/ngbcQlZ9O8Yzuq9aVw2tDMiwpiekXy1M5mEjAK6tA05oezbaw7RPiyQ168ZgcNuo6y8ghve3sCjS7bTtW0oZ/eMtOAd1W7ZliTuXRRHeYVhVGwkU87owIjubSktr6CwpJzSckPv6FZEhwcB8PhnO1m9N42/zRjMrLO6MPusLixYc5Bnvt7Dit2pOANsDO/aBmeAjR/3p1NS5vpr/emv9zCudztuPCcWgK92JvP1zuQT+nPuubAPrQIb/1dWRLj9/N6EBzv4wyc7uObNdfSMasWqPakcySrEJjBzeAx3X9iHjhHBHE4v4Nlv9rA07gieKkfdIkPoEx3G75Zup02IkylndGz0mFXz5St7QYAmiAa7ZHBHHv90J4s2JDJ5YDQFJeVV/Q9je7UDXP0QV7Q9vp38QFo+K/ekcvcFfXC4F+AKsNt48aqhzHh5Db95dyNLbx1L93Z1brPhFf/9OZk9yXnMGBZTtX7RG98f4InPdjKye1tG92jL59uO8vtPPG/J0bl1MLHtQvk+Po1bxvdg1lmuoaMBdhvzxvXgirO6sP5gBmvi0/lxfzpFpeVcPaob5/WLom90GB9uTOTtNQe57q31AIQ67Uzo257RPSMJddpxBtgIcdo5p1fj7RjoyTVndyc8yMF9H25hx5FsxvZqx23n9eJAWh5vrznEJ3FJjO8TxXe7U7DbhFvG92RIl9ak5RWTnldCgF2Y2L89faPDKCqt4Oo31vLbhXG0DnYwxv27kVdcxpHMQnq1b4XdpiOn1ImyCkpwBtgI9oEtBqQ5jd4YMWKE2bBhg9efc++iLXy54xgXD+rAp1uTiPvDJIIcdowxjPyfbzm7RyTPXzn0uDJ/+nQH//7pED88dD7tw4KOu3Y4vYDpL/9A6xAHS24d26RL/CZkFDDp2VUUlpbjsAuTB3agdYiDf/90mIsGduC52UOq2vz3JOeyJzmXoAA7wU47IrAzKYfNCVnEHc5iWLc2PHfFkFP64Cspq+CbXckEOWyM6dnO0v03copKCQqwHzf5LiGjgGe+3sOXO44xfWhn7prYu6rmVJusghJmvfojSVlFXDumG+sPZLLpcGbVZvTn9onivH7tmTywg+43oqo8sHgLK/eksvaRC5rkeSKy0RgzwtM1rUGcglkjYvhoUyIfbkzkgv7RVf+4K5uZfohPxxhTNbY+v7iMxRsSmXJGxxOSA0DXyBBeuXo4s1/7kZdXxPPwlP5N8j6MMTz88TZsAu/NG8U3u1JYvDGBnKIy5o7uxmOXDjzuw75PdBh9oo+fGjOmZ7tGicUZYPOZppjwoBMTdJe2ITx7xZAGvU7rECfv3DCKGf9Yw8vf7WNgp3DmjetBj6hQftqXznd7Ulkal8S43u1449qzPM4GVy1PZkGpT4xgAk0Qp2RkbFu6R4ZwML2Aif3bH3dtbM92fBKXxN6UvKoP0yWbj5BbXMY1Z3ev8zWnDenMOz8e4qbxPWjXyvtLVX+4IZHv49N4YvogxvRqx5he7bh/cl9+PpbDkC6tdfJYI+gQEcR/fjuOsnJD22qdjrNGdKGiwvD++sM8umQ7D320ladnnak/c0VWQYlPjGACHcV0SkSEq0Z1xWm3MbHf8QliTC9XR/MP8a7RTMYY3vnxIGd0jmBY19Z1vu7t5/eiuKyc11ft90rc1SXnFPHE5zsZGduWOdXmFQQ77Qzt2kY/qBpReJDjuORQyWYT5ozqxr0XukZQ/f3L3RZEp3yN1iCagXnn9OCSwZ1oX6MdOqZNCF3bhvD6qv0sjUsiMaOA9PwS/j5z8Ek/dHtGteLSMzvxzo+HuHl8DyK9VIswxvC7pdspKavgrzMGn7C2lGpat5/fi2M5Rbz83T46RATVWdNUzV+Wj+wFAVqDOGU2m9Cptef1Cq8a1ZUgh53woAAmDYzm8WkDuXxY/dYOuv383hSVlfPa6vrVIorLyknKKqz3ZLSKCsMfl+3g653J3DupD7EWjJpSxxMRHp82iAv6t+eJz3Z6nBeiWgZjjLsG4RtNTFqD8IL55/Zk/rk9T6lsr/atmDq4E//68RA3j3PVIlJzi8krLvP4Yf7g4q0sjUsiPCiA/h3D6dchjIhgB0FOO8EOOwM7RXBWd1eTUXmF4dEl21i4PoGbxsVy07gep/tWVSOx24S/zTyTC55ZyQMfbeXj34zRYbAtUE5RGeUVRpuYVO3unNiLT7cmMeMfa8gtKiM9vwQR+Pg3YxjatU3VfYfS81m2JYkL+kcTHR7IzqM5fLTpCHnFZce9Xte2IcwcHsP+1DyWxiVxx/m9uOfCPtrP4GPahjp57NKB3Pn+Zt764QDzNIG3OJWzqH2lk1oThA/q1T6MW8b35Kf96YyKjaRPhzD+8V08f/3iZ96/aXTVB/trq/YTYLPxP5cNOq4vxBhDsXtN+ZW7U1m8MZFnvt4DwH2T+nD7+b0teV/q5KYO7siyuCM89dVuJg3oQNfIE2fkq+brl1nUWoNQdXjo4n7HHQfYhD8u28HKPalM6Nue1NxiPtyYyOXDOp/QUS4iBDnsBDnszBgew4zhMSRkFJCYWehzy3mo44kIT0wfxIXPrOLhJVv5942jtKbXgmRWrcPkGzUI7aT2E1eO7ErXtiH89YvdVFQYFqw5QGl5BTePr18zRJe2IZoc/ETHiGAentKPH+LTWRp35OQFVLPxSxOTb9QgNEH4CWeAjXsn9WHX0RzeX3+Yf/14iMkDOtAjqpXVoSkvuPKsrgyOieAv//mZ/Bp9Sqr5ysz3rSYmTRB+ZOrgTvTvGM7vl24np6iM+RNObaSU8n02m/DHqQNJzinmlZX7rA5HNZGsAteAlKZcj60umiD8iM0mPHBRXyoMjO7RliFdWlsdkvKi4d3aMH1IJ15dtZ+EDM97UqjmJbOglPAgh88McdYE4Wcm9IniD5cM4PFpg6wORTWBBy/uh12E//3PLqtDUU0gs6DEZybJgSYIvyMi3HBO7AmrqqrmqWNEMLdO6MnybcdYuSfV6nCUl2UVlPpMBzV4OUGIyEUisltE4kXkIQ/X7xeROPfXdhEpF5G27msHRWSb+5r3N3lQykfdNL4H3SJDuO6tddz34RaOZBVaHZLykhZTgxARO/AScDEwALhSRAZUv8cY83djzBBjzBDgYWClMSaj2i3nua973MxCqZYgyGFn6a1jmXdOLMvikjjvqe946svd9V5/S/mub3YmM/eNtSRmuvqYsnxoJVfwbg1iJBBvjNlvjCkBFgLT6rj/SuB9L8ajlN9qE+rk0V8NYMX9E5g8sAMvrojni+3HrA5LnaYX/rvXta/9y2vYfiSbTB9ayRW8myA6AwnVjhPd504gIiHARcBH1U4b4CsR2SgiN9f2EBG5WUQ2iMiG1FRto1XNW+fWwTw760z6dwznic92UlhSbnVI6hTFp+SyJTGbOaO64rAJV7z6IwUl5S2jiQnwNE6rtjrxVOCHGs1LY40xw3A1Ud0mIuM9FTTGvGaMGWGMGREV5d1N7ZXyBQF2G3+6dCBJ2UW8/F281eGoU7R44xHsNuG3F/RhyW1j6RrpWq25tYfNpazizQSRCHSpdhwDJNVy72xqNC8ZY5Lc/00BluBqslJK4dqidvqQTry6cj8H0/KtDkc1UHmFYenmI5zbJ4qosECiw4NYdMto7pzYm0kDoq0Or4o3E8R6oLeIxIqIE1cSWFbzJhGJAM4FPql2LlREwiq/ByYB270Yq1J+5+Ep/XHYhSc+22l1KKqB1uxL41hOETOqbSQWFuTgngv7EF1j8U0reS1BGGPKgNuBL4FdwCJjzA4RmS8i86vdehnwlTGm+p9B0cD3IrIFWAd8boz5wluxKuWPosODuOuC3nz7cwpfbD9qdTiqAT7amEh4UAAT+7c/+c0W8upy38aY5cDyGudeqXG8AFhQ49x+4ExvxqZUc3DdmFiWbUnigcVbGdgpgi5tdf8IX5dbVMoXO45x+bAYghx2q8Opk86kVsqPOQNsvHTVMIyB29/fTElZhdUhqZP4z7ZjFJVWHNe85Ks0QSjl57pFhvK3mYPZkpDFX7/42epwlAel5RXEJWTxz9X7efm7eGLbhTKsa2urwzop3VFOqWbg4jM6ct2Y7rzx/QGGdGnN1DM7WR2SctuXmsf0l34gt8i1r0e3yBAeubifX+wUqAlCqWbi4Sn92JyQxR3vb2bp5iPcN7kv/TuGWx1Wi7clIYvcojL+fNkgLugf7VOjlE5Gm5iUaiYCA+wsvGk0D1zUl/UHM5jy/Gru/iCOzPwSq0Nr0RIyChGBmcNj/Co5gCYIpZqVYKedWyf0YvUD5zP/3J58vvUov3p+NZsOZ1odWouVkFlAdFgQgQG+PWLJE00QSjVDESEOHryoHx/9Zgx2uzDrlR/55+r9ugKsBRIyCujSNtjqME6JJgilmrEzYiL47I5xnN+vPU9+vounv9pjdUgtTmJmIV3a+Of8FE0QSjVzEcEOXp07nMuHdeaVlfuIT8m1OqQWo6SsgqPZhcT46QRGTRBKtQAiwqNT+hPitPOHT3ZoU1MTScoqpMJAlzbaxKSU8mGRrQK5/6J+rNmXzqdbde2mppDg3inOX5dA0QShVAty1ciuDOoczpOf7SSvuMzqcJq9hAzX/uGaIJRSPs9uE56YNoiU3OJf9rXeugieHQSPtXb9d+siq8NsNhIyC3DYhQ5+Nv+hks6kVqqFGdq1DXNGdWXBmoNE7v+E2/Kex1bm+kuX7AT49E7X94NnWRdkM5GQUUCn1sHYbb6/rIYnWoNQqgV6fNognpw+iBlZb/ySHCqVFsK3j1sTWDOT4MdDXEEThFItkt0mXD26Gx1J93xDdmLTBtRMJfrxJDnQBKFUiyYRtexJUNt5VW/5xWWk55cQozUIpZRfmvgHcNT4C9cR7DqvTktipn+PYAJNEEq1bINnwdTnIaILBiHRtCNp/N+0g7oRJGS450D46SQ50FFMSqnBs2DwLLILSpjytxUM3duGt8dZHZT/8/dJcqA1CKWUW+sQJ3dO7M3KPaksWp/AkaxCyit0SY5TlZBRSLDDTmSo0+pQTpnWIJRSVeae3Y331h7mgY+2AuCwC/06hPPUr8+kb4cwi6PzLwmZrhFM/rC1aG00QSilqgQG2Fl6+1jiDmeRmFlIQmYBH21M5PKXf+CFq4Zyfr9oq0P0GwkZBX49BwI0QSilaggPcjC+T1TV8TVnd+OmdzZw49sbeOTi/swbF+vXfxU3BWMMiZmFjO4RaXUop0X7IJRSdeoYEcyiW87m4kEd+PPyXdz34VaKSsutDsunZRWUkldcRowfj2ACTRBKqXoIcQbw4pXDuGtibz7alMgVr/7I0ezCkxdsoQ5n+P8IJtAEoZSqJ5tNuPvCPrw2dzj7UvOZ+sL3bDiY0eDX2ZucS0lZhRci9B1VQ1z9vA9CE4RSqkEmDezA0tvGEBbkYN47G8gpKq1XOWMMf//yZy58dhUXPruST+KOUNFMh9H+sg+ENjEppVqYXu3DeOHKoWQVlPLPVftPen9peQUPLN7KSyv28avBHQlxBnDXwjh+9cL3rN1fy4KBfsoYw/akbFqHOAgLclgdzmnRBKGUOiWDOkdwyeCO/PP7A6TmFtd6X0FJGTe/s4EPNyZy18TevHjlUD6/4xz+b/YQcotKmfvGOlbuSW3CyL2nosLwp0938vnWo0w7s5PV4Zw2ryYIEblIRHaLSLyIPOTh+v0iEuf+2i4i5SLStj5llVLWu3dSX4rLKnjxv3trvecPn+xg5Z5U/ueyM7j7wj6ICDabMG1IZz674xx6tW/Fze9s4Pu9aU0YeeMrLivnzoWbWbDmIPPOieWPUwdaHdJp81qCEBE78BJwMTAAuFJEBlS/xxjzd2PMEGPMEOBhYKUxJqM+ZZVS1ottF8oVZ3XhvXWHOZxecML1zYczWbwxkZvH9+SqUV1PuN46xMm780YR2y6Uee+sZ80+/0wSxhhufmcjn209yiNT+vG7SwZg89Nd5KrzZg1iJBBvjNlvjCkBFgLT6rj/SuD9UyyrlLLIXRN7YxPh2W/2HHe+osLw2LIdRIcHcsf5vWot3ybUlSS6tg3hxgUbWHeg4SOjrBafksfKPancP7kvN4/vaXU4jcabCaIzkFDtONF97gQiEgJcBHx0CmVvFpENIrIhNbV5tGMq5U+iw4O4fmwsS+OO8P66wxjjGpm0eFMiWxKzeejifoQG1r1oQ2SrQN6dN5pOrYO4/q11bD6c2RShN5qf3EntksEdLY6kcXkzQXiqX9U2pm0q8IMxpvJPh3qXNca8ZowZYYwZERUV5ekWpZSX3XZeT8b2bMfDH2/j7g/iOJZdxN+++JlhXVszfYjHv+1OEBUWyHs3jaZdWCDXvrmO7UeyvRx141m7P50O4UF09fOJcTV5M0EkAl2qHccASbXcO5tfmpcaWlYpZbGwIAdv3zCSey7sw7ItSUx4agXp+SX86dJBDVq3KTo8iHfnjSIsyMHcN9b6RZIwxrD2QAajerRtdmtUeTNBrAd6i0isiDhxJYFlNW8SkQjgXOCThpZVSvkOu024c2Jv3p03mjYhTq49uztnxEQ0+HVi2oTw3k2jCHLYufzlNfxz9X6fnlB3IC2f1NxiRsX698J8nnhtNVdjTJmI3A58CdiBN40xO0Rkvvv6K+5bLwO+Msbkn6yst2JVSjWes3tG8sOD53M6f0x3iwzl8zvH8cDirTz5+S5W7U3jqV8Ppn1YUOMF2kjWuvsfRvVoa3EkjU8qO5SagxEjRpgNGzZYHYZSqpEYY3h37WGe+GwnxsBZsW04t08U5/VtT+9o39jA6LcLN/N9fDrrH53ol01MIrLRGDPC0zWdSa2U8lkiwtWju7H8rnFcP7Y76Xkl/M9y13pOjy3bQWm5tYv+VfU/xDa//gfQDYOUUn6gZ1QrHp7Sn4en9OdodiGvrtzPgjUH2XU0h5fnDCOyVaAlcSVkFHI0u6hZNi9BC0gQpaWlJCYmUlRUZHUolggKCiImJgaHw78XDVOqUseIYB67dCCDYyJ4+ONtTH3he/5x9XDO7NK6yWP56YBrocHm2EENLSBBJCYmEhYWRvfu3ZtlFbAuxhjS09NJTEwkNjbW6nCUalSXD4uhd/swbvnXBmb8Yw33TOrDLeN7Ym/CJS7W7s+gTYiD3u1bNdkzm1Kz74MoKioiMjKyxSUHcLXfRkZGttjak2r+zoiJYPld45g0MJq/fbGbK1//iSNZTbfT3doD6YyMbdss1l3ypNknCKBFJodKLfm9q5ahdYiTl64axt9nDmbHkWwufm4VP+7z/h4TR7IKScwsbLbNS9BCEoRSqnkTEX49ogvL7xpH+/AgrnlzLR9vSvTa8w6nF/DkZzuB5jn/oVKz74PwN61atSIvL4+DBw9yySWXsH37dqtDUspvdIsM5aP5Y5j/743cs2gLhzMKuGti71OuSZdXGJZvO0pRaTmtAgMIdtr5z7ZjfLQpEZtN+M2EngzoGN7I78J3aIKoaesi+PZxyE6EiBiY+AcYPMvqqJRS9RQR4loX6qGPt/LcN3v5Zlcyt4zvycWDOhBgb1ijyROf7WTBmoPHnXMG2Lh6dDfmn9uTDhG+N7O7MWmCqG7rIvj0Tih1d3JlJ7iO4ZSTxIMPPki3bt249dZbAXjssccQEVatWkVmZialpaU8+eSTTJtW+3YX5eXlPPTQQ3z33XcUFxdz2223ccsttzB37lxmzpxZVXbOnDlcccUVXHrppacUq1LNhTPAxtO/PpPRPSJ55bt93PH+Zrq0DeaO83rz6xEx9apRvPXDARasOcgNY2O5fmx38orLyCsuo1tkiE8u+eEN2gdR3beP/5IcKpUWus6fotmzZ/PBBx9UHS9atIjrr7+eJUuWsGnTJlasWMG9995LXUuevPHGG0RERLB+/XrWr1/P66+/zoEDB5g3bx5vvfUWANnZ2axZs4YpU6accqxKNSciwqwRXfjmnnN5de5w2oYG8sBHW7n2rfUcy657ZN83O5N54rOdTBoQzaO/6k+XtiH07xjOWd3btpjkAJogjpddS6dWbefrYejQoaSkpJCUlMSWLVto06YNHTt25JFHHmHw4MFccMEFHDlyhOTk5Fpf46uvvuKdd95hyJAhjBo1ivT0dPbu3cu5555LfHw8KSkpvP/++8yYMYOAAK0UKlWdzSZMHtiBJb8Zw+PTBrLuQDqTnl3J0s1HPN6/JSGLO97fzKDOETw3e0iTzqvwNfppUl1EjKtZydP50zBz5kwWL17MsWPHmD17Nu+++y6pqals3LgRh8NB9+7d65yrYIzhhRdeYPLkySdcmzt3Lu+++y4LFy7kzTffPK04lWrObDbhmrO7M653FPcuiuO3H8TxQ3waT0wfRJDDDsDXO5O58/3NtA118s9rRxDibNkfkVqDqG7iH8ARfPw5R7Dr/GmYPXs2CxcuZPHixcycOZPs7Gzat2+Pw+FgxYoVHDp0qM7ykydP5h//+AelpaUA7Nmzh/x81+ro1113Hc899xwAAwcOPK04lWoJYtuF8uH8Mdx5fi8+3JjIZS+v4VB6Pq+t2sfN/9pAn+hWLLl1TItqSqpNy06PNVV2RDfyKKaBAweSm5tL586d6dixI3PmzGHq1KmMGDGCIUOG0K9fvzrLz5s3j4MHDzJs2DCMMURFRbF06VIAoqOj6d+/P9OnTz+tGJVqSew24Z5JfRnStTV3f7CFC59ZRUl5BVPO6MDTvx5CsNNudYg+odnvB7Fr1y769+9vUUTeV1BQwBlnnMGmTZuIiPC8e1dz/xkodToSMgp4ZMk2hndrw53n9262y2bUpq79ILQG4ce++eYbbrjhBu65555ak4NSqm5d2obwrxtHWR2GT9IE4ccuuOACDh8+bHUYSqlmqkV0UjenZrSGasnvXSl1epp9gggKCiI9Pb1FflBW7gcRFKSjMZRSDdfsm5hiYmJITEwkNTXV6lAsUbmjnFJKNVSzTxAOh0N3U1NKqVPQ7JuYlFJKnRpNEEoppTzSBKGUUsqjZjWTWkRSgUNABJDtPn2y7yv/2w5Ia+Ajq79efa7VPFfXcc34mjLO+sbWlHHWdr2hcXqKuaGxNnacnmJqjDhPFqv+jurvKEA3Y0yUx7uMMc3uC3itvt9X+++G03lOfa7VPFfXsYf4mizO+sbWlHGeys/UW//vGztOTzFZ9f9ef0db7u+op6/m2sT0aQO+r37udJ5Tn2s1z9V1XDO+pozT0/n6/hy9FWdt1xsaZ/XvTzXWxo6z+rH+jtb/mv6ONiyOhlwHmlkT0+kQkQ2mlgWrfInG2fj8JVaNs3H5S5xgXazNtQZxKl6zOoB60jgbn7/EqnE2Ln+JEyyKVWsQSimlPNIahFJKKY80QSillPJIE4RSSimPNEHUg4iME5FXROSfIrLG6nhqIyI2EfmziLwgItdaHU9tRGSCiKx2/0wnWB1PXUQkVEQ2isglVsdSFxHp7/55LhaR31gdT21EZLqIvC4in4jIJKvjqY2I9BCRN0RksdWx1OT+nXzb/XOc481nNfsEISJvikiKiGyvcf4iEdktIvEi8lBdr2GMWW2MmQ98Brztq3EC04DOQCmQ6MNxGiAPCPLxOAEeBBZ5I8ZqMTXG7+gu9+/oLMArwyEbKc6lxpibgOuAK3w4zv3GmBu9EZ8nDYz5cmCx++d4qVcDa+hMQn/7AsYDw4Dt1c7ZgX1AD8AJbAEGAGfgSgLVv9pXK7cICPfVOIGHgFvcZRf7cJw2d7lo4F0fjvMCYDauD7NLfP13FNeHxRrgKl+O013uaWCYH8TplX9Hpxnzw8AQ9z3veTOuZr8fhDFmlYh0r3F6JBBvjNkPICILgWnGmP8FPDYliEhXINsYk+OrcYpIIlDiPiz31TiryQQCfTVOETkPCMX1j7JQRJYbYyp8MVb36ywDlonI58B7vhiniAjwF+A/xphNjR1jY8XZ1BoSM65adwwQh5dbgZp9gqhFZyCh2nEiMOokZW4E3vJaRJ41NM6PgRdEZBywypuB1dCgOEXkcmAy0Bp40auRHa9BcRpjHgUQkeuANG8khzo09Gc6AVfTQyCw3JuB1dDQ39E7cNXMIkSklzHmFW8GV01Df56RwJ+BoSLysDuRNLXaYn4eeFFEfsXpLRtyUi01QYiHc3XOGDTG/NFLsdSlQXEaYwpwJbKm1tA4P8aVzJpag/+/AxhjFjR+KCfV0J/pd8B33gqmDg2N83lcH3BNraFxpgPzvRdOvXiM2RiTD1zfFAE0+07qWiQCXaodxwBJFsVSF42zcflLnOA/sWqc3mN5zC01QawHeotIrIg4cXVELrM4Jk80zsblL3GC/8SqcXqP9TE3RQ+9lV/A+8BRfhn6eaP7/BRgD65RAo9qnBqnxqpxaszHf+lifUoppTxqqU1MSimlTkIThFJKKY80QSillPJIE4RSSimPNEEopZTySBOEUkopjzRBqGZNRPKa+HmNsl+IuPbMyBaRzSLys4g8VY8y00VkQGM8XynQBKFUg4hIneuXGWPGNOLjVhtjhgJDgUtEZOxJ7p+Oa+VZpRpFS12sT7VgItITeAmIAgqAm4wxP4vIVOB3uNbeTwfmGGOSReQxoBPQHUgTkT1AV1zr9HcFnjOuRegQkTxjTCv36qqPAWnAIGAjcLUxxojIFOAZ97VNQA9jTK1LThtjCkUkDtfqnojITcDN7jjjgbnAEFz7QZwrIr8DZriLn/A+T/XnploerUGolug14A5jzHDgPuBl9/nvgdHuv9oXAg9UKzMc1/4BV7mP++Fasnwk8EcRcXh4zlDgt7j+qu8BjBWRIOBV4GJjzDm4PrzrJCJtgN78soT7x8aYs4wxZwK7cC3LsAbXOj33G2OGGGP21fE+laoXrUGoFkVEWgFjgA9de9cAv2xaFAN8ICIdcf11fqBa0WXGmMJqx58bY4qBYhFJwbU7Xs3tU9cZYxLdz43DVQPJA/YbYypf+31ctQFPxonIVqAv8BdjzDH3+UEi8iSu/TRaAV828H0qVS+aIFRLYwOyjDFDPFx7AXjGGLOsWhNRpfwa9xZX+74cz/+WPN3jaY3/2qw2xlwiIn2A70VkiTEmDlgATDfGbHFvZjTBQ9m63qdS9aJNTKpFMa4tYw+IyK/BtQWmiJzpvhwBHHF/f62XQvgZ6FFte8krTlbAGLMH+F/gQfepMOCou1lrTrVbc93XTvY+laoXTRCquQsRkcRqX/fg+lC9UUS2ADtw7fMLrhrDhyKyGlcHcqNzN1PdCnwhIt8DyUB2PYq+AowXkVjg98Ba4GtcCafSQuB+99DYntT+PpWqF13uW6kmJiKtjDF54uoceAnYa4x51uq4lKpJaxBKNb2b3J3WO3A1a71qbThKeaY1CKWUUh5pDUIppZRHmiCUUkp5pAlCKaWUR5oglFJKeaQJQimllEeaIJRSSnn0/5ChnwoTwG9rAAAAAElFTkSuQmCC%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">base_lr</span><span class="o">=</span><span class="mf">3e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.510850</td>
      <td>0.458526</td>
      <td>0.777000</td>
      <td>00:45</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.391805</td>
      <td>0.325548</td>
      <td>0.858000</td>
      <td>01:53</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.323382</td>
      <td>0.286508</td>
      <td>0.883500</td>
      <td>01:53</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.265536</td>
      <td>0.264187</td>
      <td>0.892000</td>
      <td>01:54</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.230185</td>
      <td>0.256429</td>
      <td>0.898500</td>
      <td>01:54</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.202922</td>
      <td>0.268608</td>
      <td>0.897500</td>
      <td>01:54</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>Compare the results of this model with the previous one we built with pure PyTorch. We can see regularization come into effect!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="7.-Using-a-Language-Model-via-DistilBERT-[HuggingFace-&amp;-PyTorch-&amp;-fastai]">
<a class="anchor" href="#7.-Using-a-Language-Model-via-DistilBERT-%5BHuggingFace-&amp;-PyTorch-&amp;-fastai%5D" aria-hidden="true"><span class="octicon octicon-link"></span></a>7. Using a Language Model via DistilBERT [HuggingFace &amp; PyTorch &amp; fastai]<a class="anchor-link" href="#7.-Using-a-Language-Model-via-DistilBERT-%5BHuggingFace-&amp;-PyTorch-&amp;-fastai%5D"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can load up a tokenizer and transformer from <a href="https://huggingface.co/transformers/">HuggingFace's Transformers API</a> and train them using fastai! We'll be using <a href="https://huggingface.co/transformers/model_doc/distilbert.html">DistilBERT</a> as it's smaller and faster than the original <a href="https://huggingface.co/transformers/model_doc/bert.html">BERT</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>"<a href="https://huggingface.co/transformers/model_doc/distilbert.html">DistilBERT</a> is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than <code>bert-base-uncased</code>, runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark."</p>
</blockquote>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">hf_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"distilbert-base-uncased"</span><span class="p">)</span>
<span class="n">hf_model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">"distilbert-base-uncased"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_text</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">sample_text</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer_outputs</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">)</span>
<span class="n">tokenizer_outputs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{'input_ids': tensor([[  101,  2023,  2614,  2650,  2001,  3376,   999,  2009, 23262,  1996,
         12411,  7301,  1999,  2115,  2568,  2061,  2092,  1045,  2052, 28667,
          8462,  4859,  2009,  2130,  2000,  2111,  2040,  5223,  6819,  2094,
          1012,  2208,  2189,   999,  1045,  2031,  2209,  1996,  2208, 10381,
          4948,  2080,  2892,  2021,  2041,  1997,  2035,  1997,  1996,  2399,
          1045,  2031,  2412,  2209,  2009,  2038,  1996,  2190,  2189,   999,
          2009, 10457,  2185,  2013, 13587,  9019,  2075,  1998,  3138,  1037,
          4840,  2121,  3357,  2007, 24665,  3686,  7334,  1998,  3969,  3993,
         19505,  1012,  2009,  2052, 17894,  3087,  2040, 14977,  2000,  4952,
           999,  1034,  1035,  1034,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer_outputs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tokenizer_outputs</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([1, 95]), torch.Size([1, 95]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>We can see that bert’s tokenizer returns 2 items, <code>input_ids</code> (numericalization of tokens) and <code>attention_mask</code> (manually lets you control attention on specific tokens). DistilBERT will take both of these as input!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's go ahead and put this into another dataset class:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">HF_Dataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hf_tokenizer</span> <span class="o">=</span> <span class="n">hf_tokenizer</span>
        
        <span class="c1"># label 1 is negative sentiment and label 2 is positive sentiment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
        
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">):</span>
        <span class="k">return</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tokenizer_outputs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]])</span>
    
    <span class="k">def</span> <span class="nf">decode_to_original</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hf_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">token_ids</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">label</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_map</span><span class="p">[</span><span class="n">label</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="n">tokenizer_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hf_tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">"pt"</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'max_length'</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
        
        <span class="n">tokenizer_output</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze_</span><span class="p">()</span>
        <span class="n">tokenizer_output</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze_</span><span class="p">()</span>
        
        <span class="k">return</span> <span class="n">tokenizer_output</span><span class="p">,</span> <span class="n">label</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">HF_Dataset</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">HF_Dataset</span><span class="p">(</span><span class="n">valid_df</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(40000, 2000)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer_outputs</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">tokenizer_outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">label</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(dict_keys(['input_ids', 'attention_mask']), tensor(1))</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenizer_outputs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">])[:</span><span class="mi">500</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'[CLS] this sound track was beautiful ! it paints the sen ##ery in your mind so well i would rec ##ome ##nd it even to people who hate vi ##d . game music ! i have played the game ch ##ron ##o cross but out of all of the games i have ever played it has the best music ! it backs away from crude keyboard ##ing and takes a fresh ##er step with gr ##ate guitars and soul ##ful orchestras . it would impress anyone who cares to listen ! ^ _ ^ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] ['</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash flash-success">
    <svg class="octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist octicon octicon-checklist" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M2.5 1.75a.25.25 0 01.25-.25h8.5a.25.25 0 01.25.25v7.736a.75.75 0 101.5 0V1.75A1.75 1.75 0 0011.25 0h-8.5A1.75 1.75 0 001 1.75v11.5c0 .966.784 1.75 1.75 1.75h3.17a.75.75 0 000-1.5H2.75a.25.25 0 01-.25-.25V1.75zM4.75 4a.75.75 0 000 1.5h4.5a.75.75 0 000-1.5h-4.5zM4 7.75A.75.75 0 014.75 7h2a.75.75 0 010 1.5h-2A.75.75 0 014 7.75zm11.774 3.537a.75.75 0 00-1.048-1.074L10.7 14.145 9.281 12.72a.75.75 0 00-1.062 1.058l1.943 1.95a.75.75 0 001.055.008l4.557-4.45z"></path></svg>
    <strong>Tip: </strong>Notice how DistilBERT also has a more efficient tokenizer compared to the standard tokenizer we used at the start. We can see it’s using subword tokenization (e.g. <code>keyboarding</code> -&gt; <code>keyboard</code> <code>##ing</code>, as well as <code>fresher</code> -&gt; <code>fresh</code> <code>##er</code>)
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here's the original input (tokens decoded, but without the subword tokenization showing):</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span><span class="o">.</span><span class="n">decode_to_original</span><span class="p">(</span><span class="n">tokenizer_outputs</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">])[:</span><span class="mi">500</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>'[CLS] this sound track was beautiful! it paints the senery in your mind so well i would recomend it even to people who hate vid. game music! i have played the game chrono cross but out of all of the games i have ever played it has the best music! it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. it would impress anyone who cares to listen! ^ _ ^ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] ['</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's make sure that items within the <code>tokenizer_outputs</code> dictionary can get batched together properly:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batched_data</span><span class="p">,</span> <span class="n">batched_labels</span> <span class="o">=</span> <span class="n">train_dl</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">batched_data</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">batched_data</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">batched_labels</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(dict_keys(['input_ids', 'attention_mask']),
 torch.Size([16, 512]),
 torch.Size([16]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To allow this model to be trained by fastai, we need to ensure that the model simply takes a single input, and returns the logits. We can create a small class to handle the intermediate stuff (like the decoupling of tokenizer_outputs via <code>**tokenizer_outputs</code>, and extracting the logits from the model output via <code>.logits</code>. Here's an example of a forward pass using HF's tokenizer and model:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hf_model</span><span class="p">(</span><span class="o">**</span><span class="n">batched_data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SequenceClassifierOutput(loss=None, logits=tensor([[-0.0196, -0.0800],
        [-0.1307, -0.0872],
        [-0.0604, -0.0986],
        [-0.1189, -0.0459],
        [-0.0588, -0.0984],
        [-0.0342, -0.0900],
        [-0.1314, -0.1056],
        [ 0.0286, -0.0227],
        [-0.0680, -0.0357],
        [-0.0157, -0.0817],
        [-0.0831, -0.0794],
        [-0.0725, -0.0759],
        [-0.0438, -0.1197],
        [-0.0845, -0.1267],
        [-0.0698, -0.0478],
        [-0.1017, -0.0566]], grad_fn=&lt;AddmmBackward&gt;), hidden_states=None, attentions=None)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">HF_Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">hf_model</span> <span class="o">=</span> <span class="n">hf_model</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokenizer_outputs</span><span class="p">):</span>
        
        <span class="n">model_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hf_model</span><span class="p">(</span><span class="o">**</span><span class="n">tokenizer_outputs</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">model_output</span><span class="o">.</span><span class="n">logits</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">HF_Model</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With the same data, here's an example of a forward pass with our small wrapper over the <code>hf_model</code></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batched_data</span><span class="p">)</span>
<span class="n">logits</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-0.0196, -0.0800],
        [-0.1307, -0.0872],
        [-0.0604, -0.0986],
        [-0.1189, -0.0459],
        [-0.0588, -0.0984],
        [-0.0342, -0.0900],
        [-0.1314, -0.1056],
        [ 0.0286, -0.0227],
        [-0.0680, -0.0357],
        [-0.0157, -0.0817],
        [-0.0831, -0.0794],
        [-0.0725, -0.0759],
        [-0.0438, -0.1197],
        [-0.0845, -0.1267],
        [-0.0698, -0.0478],
        [-0.1017, -0.0566]], grad_fn=&lt;AddmmBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>We no longer need double asteriks for decoupling the input data dictionary, and we don’t need to extract the logits from the output via <code>.logits</code> This allows for easy compatability with <code>fastai</code>’s <code>Learner</code> class
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have everything we need to finetune this model now!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># (doesn't automatically place model + data on gpu otherwise)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=tensor(3.6308e-05))</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.240267</td>
      <td>0.249942</td>
      <td>0.897500</td>
      <td>15:59</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.142634</td>
      <td>0.211986</td>
      <td>0.921000</td>
      <td>15:56</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.068012</td>
      <td>0.243243</td>
      <td>0.926000</td>
      <td>15:56</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="8.-Conclusion">
<a class="anchor" href="#8.-Conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>8. Conclusion<a class="anchor-link" href="#8.-Conclusion"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>We can take models written in pure PyTorch, or take existing models from elsewhere (e.g. HuggingFace), and train them with ease within fastai.</li>
<li>NLP has lots of variation in terms of tokenization methods. In my personal opinion*, libaries like fastai &amp; HuggingFace make the NLP data processing pipeline much easier/faster to get up and running!</li>
<li>Each method has it's pros and cons:<ul>
<li>DistilBERT may have performed better, but this model has a much much larger number of parameters and possibly a much larger vocabulary!</li>
<li>The runtime of DistilBERT was also much longer. ~16 minutes epochs (for a distilled transformer) vs ~2 min epochs (for a recurrent model)</li>
<li>In other tasks, it may be better to use a transformer, but for many common NLP tasks, sometimes a simpler/smaller model is good enough!</li>
<li>Even though transformers feed-forward it's input sequences in parallel (through positional encoding + self attention), they can be slower than simple recurrent networks due to their large model sizes.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>All the results in this blog post/notebook may differ between runs, and that a "perfect" hyperparameter search was not performed for any of these models. This tutorial was mainly done for showing examples of NLP pipelines using different libaries!
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Thanks for reading!!! 🙂</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="AmarSaini/Epoching-Blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Epoching-Blog/jupyter/nlp/pytorch/fastai/huggingface/2021/06/27/NLP-from-Scratch-with-PyTorch-FastAI-and-HuggingFace.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Epoching-Blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Epoching-Blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Epoching-Blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Yet Another Deep Learning Blog :)</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/AmarSaini" title="AmarSaini"><svg class="svg-icon grey"><use xlink:href="/Epoching-Blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/_epoching_" title="_epoching_"><svg class="svg-icon grey"><use xlink:href="/Epoching-Blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
